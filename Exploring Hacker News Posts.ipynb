{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "This project focuses on comparing the interactions between Queries and Showcases on Hacker News. Queries are posts whose titles are prefixed with 'Ask HN', namely by authors who are seeking answers to their respective questions. Post prefixed with 'Show HN' are Showcases, where authors intend to present something to the community, such as a project or a proposal. \n",
    "\n",
    "Both types of posts would receive replies from individuals in the Hack News community, hence the objective here would be to analyse which type of post would garner more responses, and if other factors such as creation time affect the amount of responses received.\n",
    "\n",
    "We will be using a snapshot of Hacker News articles captured in 2016, more details of this data set can be found [here](https://www.kaggle.com/hacker-news/hacker-news-posts).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header columns:\n",
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "0 malformed row(s) detected.\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "open_file = open('hacker_news.csv')\n",
    "read_file = reader(open_file)\n",
    "\n",
    "hn_list = list(read_file)\n",
    "hn_headers = hn_list[0] #header row\n",
    "hn = hn_list[1:] # actual data\n",
    "\n",
    "print('Header columns:')\n",
    "print(hn_headers)\n",
    "\n",
    "# quick check on row integrity\n",
    "index=0\n",
    "malformed_row_count = 0\n",
    "\n",
    "for i in range(len(hn)):\n",
    "    if len(hn[i]) != len(hn_headers): #check for column-count mismatch\n",
    "        print('Malformed row detected at index '+str(i))\n",
    "        malformed_row_count += 1\n",
    "print('\\n{} malformed row(s) detected.'.format(malformed_row_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column details for this data set as follows:\n",
    "\n",
    "| Column Name | Description |\n",
    "|-------------|-------------|\n",
    "| id | Unique ID of article |\n",
    "| title | Title of the post |\n",
    "| url | Hyperlink of the item being linked to |\n",
    "| num_points | Number of upvotes the post received |\n",
    "| num_comments | Number of comments the post received |\n",
    "| author | Name of the account that made the post |\n",
    "| created_at | Date and time the post was made (the time zone is Eastern Time in the US) |\n",
    "\n",
    "Since num_comments is a required column for our analysis, we also do a quick check to see if there are any invalid values present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 row(s) with malformed comment-count detected.\n"
     ]
    }
   ],
   "source": [
    "malformed_comment_count = 0\n",
    "for i in range(len(hn)):\n",
    "    if not hn[i][hn_headers.index('num_comments')].isnumeric(): #check num_comments column\n",
    "        print('Malformed comment-count detected at index '+str(i))\n",
    "        malformed_comment_count += 1\n",
    "print('\\n{} row(s) with malformed comment-count detected.'.format(malformed_comment_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have determined our data set to be free of issues, we then proceed to inspect the first 5 rows of the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st 5 rows:\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']\n"
     ]
    }
   ],
   "source": [
    "print('1st 5 rows:')\n",
    "for i in range(5):\n",
    "    print(hn[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we start to divide up the data set into 3 broad categories:\n",
    "- 'Ask' posts (queries)\n",
    "- 'Show' posts (showcases)\n",
    "- Other posts (all other articles that do not fit the above 2 categories)\n",
    "\n",
    "As mentioned earlier, queries and showcases would be prefixed with specific strings, and that would serve as a criteria for the categorisation logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'Ask' posts: 1744\n",
      "Number of 'Show' posts: 1162\n",
      "Number of other posts: 17194\n"
     ]
    }
   ],
   "source": [
    "ask_prefix = 'Ask HN'.lower()\n",
    "show_prefix = 'Show HN'.lower()\n",
    "\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for record in hn:\n",
    "    title = record[hn_headers.index('title')].lower()\n",
    "    if title.startswith(ask_prefix):\n",
    "        ask_posts.append(record)\n",
    "    elif title.startswith(show_prefix):\n",
    "        show_posts.append(record)\n",
    "    else:\n",
    "        other_posts.append(record)\n",
    "\n",
    "print('Number of \\'Ask\\' posts: {}'.format(len(ask_posts)))\n",
    "print('Number of \\'Show\\' posts: {}'.format(len(show_posts)))\n",
    "print('Number of other posts: {}'.format(len(other_posts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 3 lists of the various types of posts being built, we inspect 5 rows of the 'Ask' posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55']\n",
      "['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43']\n",
      "['11610310', 'Ask HN: Aby recent changes to CSS that broke mobile?', '', '1', '1', 'polskibus', '5/2/2016 10:14']\n",
      "['12210105', 'Ask HN: Looking for Employee #3 How do I do it?', '', '1', '3', 'sph130', '8/2/2016 14:20']\n",
      "['10394168', 'Ask HN: Someone offered to buy my browser extension from me. What now?', '', '28', '17', 'roykolak', '10/15/2015 16:38']\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(ask_posts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as 'Show' posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03']\n",
      "['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46']\n",
      "['11590768', 'Show HN: Shanhu.io, a programming playground powered by e8vm', 'https://shanhu.io', '1', '1', 'h8liu', '4/28/2016 18:05']\n",
      "['12178806', 'Show HN: Webscope  Easy way for web developers to communicate with Clients', 'http://webscopeapp.com', '3', '3', 'fastbrick', '7/28/2016 7:11']\n",
      "['10872799', 'Show HN: GeoScreenshot  Easily test Geo-IP based web pages', 'https://www.geoscreenshot.com/', '1', '9', 'kpsychwave', '1/9/2016 20:45']\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(show_posts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With each list, we can derive the average number of comments given per type of article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average number of comments per 'Ask' post: 14.04\n",
      "Average number of comments per 'Show' post: 10.32\n"
     ]
    }
   ],
   "source": [
    "import statistics as stat\n",
    "\n",
    "# derive average number of comments per 'Ask' post\n",
    "avg_ask_comments = stat.mean([int(rec[hn_headers.index('num_comments')]) for rec in ask_posts])\n",
    "\n",
    "# derive average number of comments per 'Show' post\n",
    "avg_show_comments = stat.mean([int(rec[hn_headers.index('num_comments')]) for rec in show_posts])\n",
    "\n",
    "print(' Average number of comments per \\'Ask\\' post: {:.2f}'.format(avg_ask_comments))\n",
    "print('Average number of comments per \\'Show\\' post: {:.2f}'.format(avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, a typical 'Ask' post seem to garner an average of about 4 more comments than a 'Show' post. This may arise from the possibility that 'Ask' posts tend to yield member inputs that lead to more discussion if the inputs differ from one another. On the other hand, 'Show' posts may attract one-off comments that express opinion on the given subject, with lesser chance to generate further discussion.\n",
    "\n",
    "With focus on 'Ask' posts, we now derive the average number of comments captured on an hourly basis, to see if there's a time of day where interaction rate is higher:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "# use a list to isolate out the post creation time, as well as comment count\n",
    "result_list = []\n",
    "for rec in ask_posts:\n",
    "    created_at_str = rec[hn_headers.index('created_at')]\n",
    "    comment_count = int(rec[hn_headers.index('num_comments')])\n",
    "    result_list.append([created_at_str, comment_count])\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "# With 2 dictionaries, capture the number of post at the different hour of day,\n",
    "# followed by comment-count also at different hour of day\n",
    "for rec in result_list:\n",
    "    created_at_str = rec[0]\n",
    "    count_value = rec[1]\n",
    "    dt_format = '%m/%d/%Y %H:%M' #example: 11/25/2015 14:03\n",
    "    created_at_datetime = dt.datetime.strptime(created_at_str, dt_format)\n",
    "    hour = created_at_datetime.strftime('%H')\n",
    "    if hour not in counts_by_hour.keys():\n",
    "        counts_by_hour[hour] = 1\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        \n",
    "    if hour not in comments_by_hour.keys():\n",
    "        comments_by_hour[hour] = count_value\n",
    "    else:\n",
    "        comments_by_hour[hour] += count_value\n",
    "\n",
    "# With the above 2 dictionaries, we can derive the averge number of comments \n",
    "# per post at the different times of the day\n",
    "avg_by_hour = []\n",
    "\n",
    "for key,value in comments_by_hour.items():\n",
    "    avg_by_hour.append([key, (value / counts_by_hour[key])])\n",
    "\n",
    "# Print raw findings out\n",
    "for rec in avg_by_hour:\n",
    "    print('{}: {:.2f}'.format(rec[0], rec[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the raw results, we do time conversion to ascertain the time of day in Singapore when we could publish a 'Ask' post on Hacker News to possibly garner the greatest number of comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of comments per 'Ask' post at hour of day (GMT+8):\n",
      "00:00 SST (12:00 EST): 9\n",
      "01:00 SST (13:00 EST): 15\n",
      "02:00 SST (14:00 EST): 13\n",
      "03:00 SST (15:00 EST): 39\n",
      "04:00 SST (16:00 EST): 17\n",
      "05:00 SST (17:00 EST): 11\n",
      "06:00 SST (18:00 EST): 13\n",
      "07:00 SST (19:00 EST): 11\n",
      "08:00 SST (20:00 EST): 22\n",
      "09:00 SST (21:00 EST): 16\n",
      "10:00 SST (22:00 EST): 7\n",
      "11:00 SST (23:00 EST): 8\n",
      "12:00 SST (00:00 EST): 8\n",
      "13:00 SST (01:00 EST): 11\n",
      "14:00 SST (02:00 EST): 24\n",
      "15:00 SST (03:00 EST): 8\n",
      "16:00 SST (04:00 EST): 7\n",
      "17:00 SST (05:00 EST): 10\n",
      "18:00 SST (06:00 EST): 9\n",
      "19:00 SST (07:00 EST): 8\n",
      "20:00 SST (08:00 EST): 10\n",
      "21:00 SST (09:00 EST): 6\n",
      "22:00 SST (10:00 EST): 13\n",
      "23:00 SST (11:00 EST): 11\n"
     ]
    }
   ],
   "source": [
    "# US eastern time is GMT-4, SGP time is GMT+8, i.e. 12 hours apart\n",
    "avg_by_sgp_hour = []\n",
    "for rec in avg_by_hour:\n",
    "    eastern_time_str_value = rec[0]\n",
    "    eastern_time_int_value = int(eastern_time_str_value) # convert zero-padded strings to int\n",
    "    sgp_time_int_value = (eastern_time_int_value + 12) % 24 # account for time-diff\n",
    "    sgp_time_str_value = '{0:02d}'.format(sgp_time_int_value) # convert back to zero-padded string\n",
    "    avg_by_sgp_hour.append([sgp_time_str_value, eastern_time_str_value, rec[1]]) # put results in new list\n",
    "\n",
    "# sort the list according to time of day\n",
    "sorted_avg_by_sgp_hour = sorted(avg_by_sgp_hour, key=lambda x: x[0])\n",
    "\n",
    "# print out sorted results\n",
    "print('Average number of comments per \\'Ask\\' post at hour of day:')\n",
    "for rec in sorted_avg_by_sgp_hour:\n",
    "    print('{}:00 SST ({}:00 EST): {:.0f}'.format(rec[0], rec[1], rec[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above hour-of-day tabulation, it has been shown that an 'Ask' post created at 3am local time would stand to garner the top average of 39 comments. \n",
    "\n",
    "It corresponds to 3pm in US eastern time, which might be due to site traffic being highest in mid-afternoon in the US as it is the preferred time of day for most members to browse content and interact with others within the community."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
